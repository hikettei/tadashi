#+startup: beamer
#+title: Polyhedral Tutor
#+options: h:2 ':t
#+latex_header: \usepackage[]{lmodern}
#+latex_header: \usepackage[T1]{fontenc}
#+beamer_theme: Montpellier
#+beamer_color_theme: beaver
#+latex_class_options: [serif]
#+latex_header_extra: \usepackage{concrete}
#+latex_header_extra: \usepackage[]{mathrsfs}
#+beamer_header: \setbeamercolor{math text}{fg=black!15!magenta}
#+latex_header: \def\eg{e.g.\ }
#+latex_header: \def\ie{i.e.\ }
#+latex_header: \def\pD{\mathscr{D}}
#+latex_header: \def\pR{\mathscr{R}}
#+latex_header: \def\pP{\mathscr{P}}
#+latex_header: \def\pF{\mathscr{F}}

* Intro
** Polyhedral in practice and theory
*** In practice: Make code faster
    advanced loop transformations
    - Loop permutation, vectorisation, fusion, tiling, strip-minig
*** In theory: describe and reason about loops
    to describe:
    - Sets and relations of named integer tuples, Presburger formulas,
      piece\-wise quasi-affine maps
    to reason:
    - Math/ILP $\implies$ calculus on Presburger formulas
** The process
*** Source to Source compilation (simplified)
    1. *Input*: source code ("nice" loops, ~#pragma scop~ or
       auto-detect)
    2. Problem 1: Find "nice" loops: PET *extracts* ISL named tuple
       sets/relations (and a trivial schedule)
    3. Problem 2: Find/approximate the *true dependencies*
    4. *PROBLEM 3*: Find a (transform the trivial schedule) to a
       better *(optimal) schedule* (using ILP)
    5. Problem 4: Based on the optimal schedule (and domain) *generate
       ~C~ code*
    6. *Output*: transformed loop (new ~.c~ file)

** Statements vs statement instances
   #+begin_src fortran
           do i = 0,n
      1       y(i) = 0.0
              do j = 0,n
      2          y(i) = y(i) + a(i,j)*x(j)
              end do
           end do
   #+end_src
   - Every command (in the source code) which reads/writes the memory
     is a *statement*, \eg ~1: y(i) = 0.0~
   - Each statement has multiple *instances*:
     - Statement 1 is ~y(0) = 0.0~ for ~i=0~, ~y(1) = 0.0~ for ~i=1~ etc.
   - $n$ is a *parameter*, treated as a constant, can be ignored
   - The set of instances of "nice" loops have affine description:
     - $n \mapsto \{ i : 0 \le i \le n \}$, $n \mapsto \{ (i, j) : 0
       \le i, j \le n \}$
** Literature
*** Problem 3
    - This is the central idea of polyhedral compilation
    - Other problems are also important (maybe more important, \eg
      dependency analysis), but this is the "skeleton" of the approach
      (everything else connects to it).
    - Described by: /Some Efficient Solutions to the Affine Scheduling
      Problem. I. One-Dimensional Time/ by Paul Feautrier
* Discussion of the paper
** Dependence graph
*** Generalised Dependence Graph (GDG)
    - *Vertex*: $\forall$ statement $S$ is the (family of)
      *polyhedron(s)* $\pD_S \subset \mathbb{Q}^{P_S}$, $P_S \in
      \mathbb{N}$ is the dimension of the iteration space, \ie the
      number of loops enclosing $S$. Every instance $x$ of every
      statement $S$ is described by $(S, x)$ where $x \in \pD_S$.
    - *Edge*: $\forall$ edge $e$ from (statement) $R$ to (statement)
      $S$ is the *polyhedron* $\pR_e \subset \mathbb{Q}^{P_R + P_S}$
*** Detailed Dependence Graph (DDG)
    Vertices: $\Omega = \cup_{S \in V} \{ (S, x) : x \in
    \pD_S \}$

    Edges ($\sigma(e)$ is the start, $\delta(e)$ is the end of edge
    $e$): $$\Gamma = \cup_{e \in E} \{ \langle (\sigma(e), x),
    (\delta(e), y) \rangle : x \in \pD_{\sigma(e)}, y \in
    \pD_{\delta(e)}, \langle x, y \rangle \in \pR_e \}$$
** Vertex polyhedron example
   #+begin_src fortran
           do i = 0,n
      1       y(i) = 0.0
              do j = 0,n
      2          y(i) = y(i) + a(i,j)*x(j)
              end do
           end do
   #+end_src
   - $\pD_1 = \{ i : 0 \le i \le n \}$
   - $\pD_2 = \{ (i, j) : 0 \le i, j \le n \}$
   - $\langle i', i, j \rangle \in \pR_{1,2} \iff i' = i$
   - $\langle i', j', i, j \rangle \in \pR_{2,2} \iff i' = i
     \land j' < j$
** Schedule
*** The map from statements instances to dates
    - A *schedule* describes when an instance of a statement will be
      described: $\theta(S, x) = t$ is the /date/ of the instance.
    - Trivial schedule: $u, v \in \Omega, u \Gamma v \implies
      \theta(u) + 1 \ge \theta(v)$
*** Simplified "code generation"
    Let $\pF(t) = \{ u \in \Omega : \theta(u) = t \}$ and $L =
    \max_{u \in \Omega} \theta(u)$.
    - ~do~ $t = 0, L$
      - ~doall~ $\pF(t)$
      - ~barrier~
    - ~end do~
** Impossibility theorems, Proposed solution
*** Impossibility theorems
    - The consistency problem for a nonuniform GDG with at least one
      infinite domain is undecidable.
    - The consistency problem for an infinite family of nonuniform GDG
      with finite domains is undecidable.
*** Proposed solution
    Look for an affine schedule only: $\theta(S, x) = \tau_S x +
    \sigma_S n + \alpha_S$
    - Note: we can drop the integer constraints
    - $\theta(S, \cdot)$ is described by $(\tau_S, \sigma_S,
      \alpha_S)$
** First steps towards parallel programs
*** Depth etc.
    - *Depth* of edge $e$: $p_e \in \mathbb{N}$ such that $\langle x,
      y \rangle \in \pR_e \iff x[1 \ldots p_e] = y[1 \ldots
      p_e] \land x[p_e + 1] < y[p_e + 1]$
    - *Dependence direction vectors* (DDV): $\langle \overbrace{=,
      \cdots, =}^{p_e}, <, *, \cdots \rangle$
    - If $y = x + d$ the dependency is *uniform* resulting in a
      *dependency cone*.
    - Reduce $\pR_e$ to a minimal form: polyhedron
      $\pP_e$ and an affine transformation $h_e$ such that:
      - $\langle x, y \rangle \in \pR_e \iff (x = h_e(y)
        \land y \in \pP_e$
      - then $y \in \pP_e \implies y \in \pD_{\delta(e)} \land h_e(y)
        \in \pD_{\sigma(e)}$
** Dependency analysis example
   #+begin_src fortran
           do i = 0,n
      1       y(i) = 0.0
              do j = 0,n
      2          y(i) = y(i) + a(i,j)*x(j)
              end do
           end do
   #+end_src
   - $\pD_1 = \{ i : 0 \le i \le n \}$, $\pD_2 = \{ (i, j) : 0 \le i, j \le n \}$
   - Standard analysis (depth $1$ because of $i' = i$, \(i\)-loop can
     be parallel)
     - $\langle i', i, j \rangle \in \pR_{1,2} \iff i' = i$
     - $\langle i', j', i, j \rangle \in \pR_{2,2} \iff i' = i \land
       j' < j$
** Dependency analysis example
   :PROPERTIES:
   :BEAMER_ENV: fullframe
   :END:
   #+begin_src fortran
           do i = 0,n
      1       y(i) = 0.0
              do j = 0,n
      2          y(i) = y(i) + a(i,j)*x(j)
              end do
           end do
   #+end_src
   - $\pD_1 = \{ i : 0 \le i \le n \}$, $\pD_2 = \{ (i, j) : 0 \le i, j \le n \}$
   - Dataflow:
     - $\langle i', i, j \rangle \in \pR_{1,2} \iff i' = i \land j =
       0$ (typo $j = 1$ in paper?)
     - $\pP_1 = \pD_2 \cap \{ (i, j) : j \le 0 \}$ and $h_1(i, j) =
       i$
     - $\langle i', j', i, j \rangle \in \pR_{2,2} \iff i' = i \land
       j' = j - 1 \land j \ge 1$ (typo $j \ge 2$ in paper?)
     - $\pP_2 = \pD_2 \cap \{ (i, j) : j \ge 1 \}$ and $h_2(i, j) =
       \langle i, j - 1 \rangle$
** Notation
   $\pD_S$ is defined by $(a_S, b_S)$ such that:
   $$a_{S_k} \begin{pmatrix} x \\ n \end{pmatrix} + b_{S_k} \ge 0
   \quad (\forall k=1, \ldots m_S)$$

   $\pR_e$ is defined by $(c_e, d_e)$ such that:
   $$c_{e_k} \begin{pmatrix} x \\ y \\ n \end{pmatrix} + d_{e_k} \ge 0
   \quad (\forall k=1, \ldots m_e)$$
   #
   or for a restricted schedule ($y = h_e(x)$)
   $$c_{e_k} \begin{pmatrix} x \\ n \end{pmatrix} + d_{e_k} \ge 0
   \quad (\forall k=1, \ldots m_S)$$
** Farkas algorithm
   Existance of a schedule:
   #+begin_export latex
   \begin{equation*}
   \label{eq:farkas1}
   \theta(S, x) \equiv \mu_{S_0} + \sum_{k=1}^{m_S} \mu_{S_k}
   \Bigl( a_{S_k} \begin{pmatrix} x \\ n \end{pmatrix} + b_{S_k} \Bigr)
   \end{equation*}
   #+end_export
   Optimal schedule:
   #+begin_export latex
   \begin{gather*}
   \label{eq:farkas2}
   \theta(\delta(e), y) - \theta(\sigma(e), x) - 1 \equiv
   \lambda_{e_0} + \sum_{k=1}^{m_e}
   \lambda_{e_k} \Bigl( c_{e_k} \begin{pmatrix} x \\ y \\ n \end{pmatrix} + d_{e_k} \Bigr)\\
   \label{eq:farkase}
   \theta(\delta(e), y) - \theta(\sigma(e), h_e(y)) - 1
   \equiv \lambda_{e_0} + \sum_{k=1}^{m_e}
   \lambda_{e_k} \Bigl( c_{e_k} \begin{pmatrix} x \\ n \end{pmatrix} + d_{e_k} \Bigr)
   \end{gather*}
   #+end_export

** Farkas algorithm example
   #+begin_src fortran
           do i = 0,n
      1       y(i) = 0.0
              do j = 0,n
      2          y(i) = y(i) + a(i,j)*x(j)
              end do
           end do
   #+end_src
*** Earlier:
    #+begin_export latex
    \begin{align*}
      \pD_1 &= \{ i : 0 \le i \le n \} = \{ i : 0 \le i \land 0 \le n - i \} \\
      \pD_2 &= \{ (i, j) : 0 \le i, j \le n \} \\
            &= \{ (i, j) : 0 \le i \land 0 \le n - i \land 0 \le j \land 0 \le n - j \}
    \end{align*}
    #+end_export
    - $\langle i', i, j \rangle \in \pR_{1,2} \iff i' = i$
      - $\pP_1 = \pD_2 \cap \{ (i, j) : j \le 0 \}$ and $h_1(i, j) =
        i$
    - $\langle i', j', i, j \rangle \in \pR_{2,2} \iff i' = i \land j'
      < j$
      - $\pP_2 = \pD_2 \cap \{ (i, j) : j \ge 1 \}$ and $h_2(i, j) =
        \langle i, j - 1 \rangle$

** Existence of a schedule
*** The formula:
    #+begin_export latex
    \begin{equation*}
    \label{eq:farkas1}
    \theta(S, x) \equiv \mu_{S_0} + \sum_{k=1}^{m_S} \mu_{S_k}
    \Bigl( a_{S_k} \begin{pmatrix} x \\ n \end{pmatrix} + b_{S_k} \Bigr)
    \end{equation*}
    #+end_export
*** Applied:
    #+begin_export latex
    \vspace{-2em}
    \begin{align*}
      \pD_1 &= \{ i : 0 \le i \le n \} = \{ i : 0 \le i \land 0 \le n - i \} \\
      \theta(1, i) &= \mu_{1, 0} + \mu_{1, 1} i + \mu_{1, 2} (n - i) \\
      \pD_2 &= \{ (i, j) : 0 \le i, j \le n \} \\
            &= \{ (i, j) : 0 \le i \land 0 \le n - i \land 0 \le j \land 0 \le n - j \} \\
      \theta(2, i, j) &= \mu_{2, 0} + \mu_{2, 1} i + \mu_{2, 2} (n - i) + \mu_{2, 3} j + \mu_{2, 4} (n - j)
    \end{align*}
    #+end_export

** Towards an optimal schedule
   #+begin_export latex
   \begin{gather*}
   \label{eq:farkase}
   \theta(\delta(e), y) - \theta(\sigma(e), h_e(y)) - 1
   \equiv \lambda_{e_0} + \sum_{k=1}^{m_e}
   \lambda_{e_k} \Bigl( c_{e_k} \begin{pmatrix} x \\ n \end{pmatrix} + d_{e_k} \Bigr)
   \end{gather*}
   #+end_export
*** Dataflow analysis:
    - $\pD_1 = \{ i : 0 \le i \le n \}$, $\pD_2 = \{ (i, j) : 0 \le i,
      j \le n \}$
    - $\pP_1 = \pD_2 \cap \{ (i, j) : j \le 0 \}$ and $h_1(i, j) = i$,
      $\pP_2 = \pD_2 \cap \{ (i, j) : j \ge 1 \}$ and $h_2(i, j) =
      \langle i, j - 1 \rangle$
    #+begin_export latex
    \begin{align*}
      &\mu_{2, 0} + \mu_{2, 1} i + \mu_{2, 2} (n - i) + \mu_{2, 3} j + \mu_{2, 4} (n - j) \\
      -& (\mu_{1, 0} + \mu_{1, 1} i + \mu_{1, 2} (n - i)) - 1 \\
      \equiv& \lambda_{1, 0} + \lambda_{1, 1} i + \lambda_{1, 2} (n - i) + \lambda_{1, 3} j + \lambda_{1, 4} (n - j) - \lambda_{1, 5} j
    \end{align*}
    #+end_export
** ILP setup
   #+begin_export latex
   \vspace{-2em}
   \begin{align*}
     &\mu_{2, 0} + \mu_{2, 1} i + \mu_{2, 2} (n - i) + \mu_{2, 3} j + \mu_{2, 4} (n - j) \\
     -& (\mu_{1, 0} + \mu_{1, 1} i + \mu_{1, 2} (n - i)) - 1 \\
     \equiv& \lambda_{1, 0} + \lambda_{1, 1} i + \lambda_{1, 2} (n - i) + \lambda_{1, 3} j + \lambda_{1, 4} (n - j) - \lambda_{1, 5} j
   \end{align*}
   \vspace{-2em}
   \begin{align*}
     \mu_{2, 0} - \mu_{1, 0} - 1 &= \lambda_{1, 0} &\text{const.\ terms}\\
     \mu_{2, 1} - \mu_{2, 2} - \mu_{1, 1} + \mu_{1, 2} &= \lambda_{1, 1} - \lambda_{1, 2} &\text{$i$ terms}\\
     \mu_{2, 3} - \mu_{2, 4} &= \lambda_{1, 3} - \lambda_{1, 4} - \lambda_{1, 5} &\text{$j$ terms}\\
     \mu_{2, 2} + \mu_{2, 4} - \mu_{1, 2} &= \lambda_{1, 2} + \lambda_{1, 4} &\text{$n$ terms}
   \end{align*}
   #+end_export

** ILP calculcations
   $2 \to 2$ edge is uniform, the delay doesn't depend on the
   iteration vector: $\mu_{2, 3} - \mu_{2, 4} - 1 \ge 0$. One possible
   solution:
   #+begin_export latex
   \begin{align}
     \lambda_{1, 0} =& \mu_{2, 0} - \mu_{1, 0} - 1 \ge 0 \\
     \lambda_{1, 1} =& \mu_{2, 1} + \mu_{2, 4} - \mu_{1, 1} - \lambda_{1, 4} \ge 0 \\
     \lambda_{1, 3} =& \mu_{2, 3} - \mu_{2, 4} - \lambda_{1, 4} - \lambda_{1, 5} \ge 0 \\
     \lambda_{1, 2} =& \mu_{2, 2} + \mu_{2, 4} - \mu_{1, 2} - \lambda_{1, 4} \ge 0 \\
     & \mu_{2, 3} - \mu_{2, 4} - 1 \ge 0
   \end{align}
   #+end_export

** Uniform edge explanation
   Edge $e : 2 \to 2$ is uniform, which means there is a vector $d =
   \langle 0, 1 \rangle$ such that $x = h_e(y) = y - d$, \ie $h(i, j)
   = \langle i, j - 1 \rangle$.
   #+begin_export latex
   \begin{equation*}
   \label{eq:farkas1}
   \theta(S, x) \equiv \mu_{S_0} + \sum_{k=1}^{m_S} \mu_{S_k}
   \Bigl( a_{S_k} \begin{pmatrix} x \\ n \end{pmatrix} + b_{S_k} \Bigr)
   \end{equation*}
   #+end_export
   So $\theta(\delta(e), y) - \theta(\sigma(e), h_e(y))$ is:

   $\mu_{S_0} + \sum_{k=1}^{m_S} \mu_{S_k} \bigl( a_{S_k}
   (\begin{smallmatrix} y \\ n \end{smallmatrix}) + b_{S_k} \bigr) -
   \bigl[ \mu_{S_0} + \sum_{k=1}^{m_S} \mu_{S_k} \bigl( a_{S_k}
   (\begin{smallmatrix} h(y) \\ n \end{smallmatrix}) + b_{S_k} \bigr)
   \bigr]$

   $\mu_{S_0} + \sum_{k=1}^{m_S} \mu_{S_k} \bigl( a_{S_k}
   \Bigl(\begin{smallmatrix} i \\ j \\ n \end{smallmatrix}\Bigr) +
   b_{S_k} \bigr) - \bigl[ \mu_{S_0} + \sum_{k=1}^{m_S} \mu_{S_k}
   \bigl( a_{S_k} \Bigl(\begin{smallmatrix} i \\ j-1 \\ n
   \end{smallmatrix}\Bigr) + b_{S_k} \bigr) \bigr]$

   Most of the terms cancel each other out: $- \sum_{k=1}^{m_S}
   \mu_{S_k} a_{S_k} \Bigl( \begin{smallmatrix} 0 \\ -1 \\ 0
   \end{smallmatrix} \Bigr)$, so from $\theta(2, i, j) = \cdots
   \mu_{2, 3} j + \mu_{2, 4} (n - j)$ we have: $\theta(2, y) -
   \theta(2, h(y)) = \theta(2, i, j) - \theta(2, i, j - 1) = \mu_{2,
   3} - \mu_{2, 4}$

** ILP solution
*** SRight column
    :PROPERTIES:
    :BEAMER_col: 0.45
    :END:
    #+begin_export latex
    \begin{align*}
      \mu_{2, 0} - \mu_{1, 0} - 1 \ge& 0 \\
      \mu_{2, 3} - \mu_{2, 4} - 1 \ge& 0 \\
      \mu_{2, 3} + \mu_{2, 4} - \mu_{1, 1} \ge& 0 \\
      \mu_{2, 2} + \mu_{2, 4} - \mu_{1, 2} \ge& 0
    \end{align*}
    #+end_export
*** Right column
    :PROPERTIES:
    :BEAMER_col: 0.45
    :END:
    #+begin_export latex
    \begin{align*}
      &0 \le \mu_{1, 1} \le \mu_{2, 1} + \mu_{2, 4} \\
      &0 \le \mu_{1, 2} \le \mu_{2, 2} + \mu_{2, 4} \\
      &\mu_{2, 0} \ge 1 + \mu_{1, 0} \\
      &\mu_{2, 3} \ge 1 + \mu_{2, 4}
    \end{align*}
    #+end_export
*** Solution:
    - $\mu_{1, 0} = \mu_{2, 1} = \mu_{2, 2} = \mu_{2, 4} = \mu_{1, 1} = \mu_{1, 2} = 0$
    - $\mu_{2, 0} = \mu_{2, 3} = 1$
    - $\theta(1, i) = 0$
    - $\theta(2, i, j) = j + 1$
** Generated code
    - $\theta(1, i) = 0$
    - $\theta(2, i, j) = j + 1$
   #+begin_src fortran
           doall (i = 1,n)
      1       y(i) = 0.0
           end do
           do j = 0,n
              doall (i = 1,n)
      2          y(i) = y(i) + a(i,j)*x(j)
              end do
           end do
   #+end_src
